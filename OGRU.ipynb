{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PfRYqnZV5J1M"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7OLeeo7-63PZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from scipy.io import loadmat\n",
        "import cv2\n",
        "import skimage as io\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import os\n",
        "from google.colab.patches import cv2_imshow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_V41wBT6_2L"
      },
      "outputs": [],
      "source": [
        "def RMSELoss(yhat,y):\n",
        "    return torch.sqrt(torch.mean((yhat-y)**2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgHBkc1W7C9-"
      },
      "outputs": [],
      "source": [
        "class BackgroundModel(nn.Module):\n",
        "\n",
        "\tdef __init__(self, input_size, hidden_size, num_layers):\n",
        "\t\tsuper(BackgroundModel, self).__init__()\n",
        "\t\tself.rnn = nn.GRU(input_size, hidden_size, num_layers)\n",
        "\t\tself.linear = nn.Linear(hidden_size, input_size)\n",
        "\n",
        "\tdef forward(self, x_in):\n",
        "\t\tx_in_shape = x_in\n",
        "\t\tx_input1 = x_in[0].unsqueeze(0)\n",
        "\t\tlatent, _ = self.rnn(x_input1)\n",
        "\t\tbg_es = self.linear(latent).view(x_in_shape.size())\n",
        "\t\tloss = RMSELoss(bg_es, x_input1)\n",
        "\t\treturn bg_es, loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1dENfX7xiCP"
      },
      "outputs": [],
      "source": [
        "# defining the video file path and check input shape:\n",
        "\n",
        "video_file = 'Replace the path of video'\n",
        "cap = cv2.VideoCapture(video_file)\n",
        "ret, frame = cap.read()\n",
        "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "x = torch.FloatTensor(gray).unsqueeze(0).unsqueeze(0).view(1, 1, -1)\n",
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xx3kMRQ57FlC"
      },
      "outputs": [],
      "source": [
        "path_of_org = 'Replace the path you want save the original frames'\n",
        "path_of_bg = 'Replace the path you want save the background frames'\n",
        "path_of_fg = 'Replace the path you want save the foreground frames'\n",
        "\n",
        "\n",
        "model = BackgroundModel(input_size=307200, hidden_size=40, num_layers=2)\n",
        "optimizer = torch.optim.Rprop(model.parameters(), lr=0.02)\n",
        "bg = torch.FloatTensor(np.zeros([1,307200]))\n",
        "\n",
        "\n",
        "print('loading data..')\n",
        "\n",
        "#open the video file\n",
        "cap = cv2.VideoCapture(video_file)\n",
        "\n",
        "\n",
        "print('start..')\n",
        "#read the first frame\n",
        "ret, frame = cap.read()\n",
        "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "x = torch.FloatTensor(gray).unsqueeze(0).unsqueeze(0).view(1, 1, -1)\n",
        "i = 1\n",
        "\n",
        "# loop over the frames\n",
        "while ret:\n",
        "\tprint('Frame: ', i)\n",
        "\n",
        "\t#pre-processing the frame\n",
        "\tx = torch.FloatTensor(gray).unsqueeze(0).unsqueeze(0).view(1, 1, -1)\n",
        "\n",
        "\t#passing frame through model\n",
        "\tbg_es, loss = model.forward(x)\n",
        "\n",
        "  #backpropagation\n",
        "\toptimizer.zero_grad()\n",
        "\tloss.backward()\n",
        "\toptimizer.step()\n",
        "\n",
        "\tret, frame = cap.read()\n",
        "\tgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\timg_org = x.reshape(480, 640)\n",
        "\timg_org = np.array(img_org, dtype = np.uint8)\n",
        "\tcv2.imwrite(path_of_org + str(i) + '.jpg', img_org)\n",
        "\n",
        "\tbg_result = bg_es.squeeze(dim=1)\n",
        "\timg_bg = bg_result.reshape(480, 640)\n",
        "\timg_bg = img_bg.detach().numpy()\n",
        "\timg_bg = np.array(img_bg, dtype = np.uint8)\n",
        "\tcv2.imwrite(path_of_bg + str(i) + '.jpg', img_bg)\n",
        "\n",
        "\timg_fg = cv2.subtract(img_org, img_bg)\n",
        "\tcv2.imwrite(path_of_fg + str(i) + '.jpg', img_fg)\n",
        "\n",
        "\n",
        "\timg_result = np.concatenate((img_org, img_bg, img_fg), axis=1)\n",
        "\tcv2_imshow(img_result)\n",
        "\n",
        "\ti = i+1\n",
        "#releasing video file\n",
        "cap.release()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgT7kZhoMyQq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}